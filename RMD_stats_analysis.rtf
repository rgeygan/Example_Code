{\rtf1\ansi\ansicpg1252\cocoartf2513
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 ArialMT;}
{\colortbl;\red255\green255\blue255;\red26\green26\blue26;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c13333\c13333\c13333;\cssrgb\c100000\c100000\c100000;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs20 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 ---\
output:\
\'a0 word_document: default\
\'a0 html_document: default\
---\
```\{r\}\
library(lattice)\
library(car)\
library(leaps)\
\
##read in data\
data = read.table('C:/Users/Ryan/Desktop/Stats/572/exam/draxinus_mod.csv', header = TRUE, sep = ",", dec = ".")\
\
##plot data raw\
myind = c(rep(1,40), rep(2,40), rep(3,40))\
plot(jitter(y)~x3, pch=myind, col=myind, data=data)\
plot(jitter(y)~x4, pch=myind, col=myind, data=data)\
plot(jitter(y)~x5, pch=myind, col=myind, data=data)\
\
##create logistic regression models\
fullmodel = glm(y~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11, family = binomial(logit), data = data)\
\
fullmodel2 = glm(y~x1+x2+x3+x4+x6+x7+x9+x10, family = binomial(logit), data = data)\
\
sameintercept = glm(y~x3+x4+x6+x7+x9+x10, family = binomial(logit), data = data)\
\
nodiff = glm(y~x3+x4, family = binomial(logit), data = data)\
\
onlyinteraction = glm(y~x5, family = binomial(logit), data = data)\
\
new = glm(y~x1+x2+x3+x4+x5, family = binomial(logit), data = data)\
\
##summary stats for each model\
summary(fullmodel)\
summary(fullmodel2)\
summary(sameintercept)\
summary(nodiff)\
summary(onlyinteraction)\
\
##test for sigificant differences between full model and reduced models (parsimony test)\
\
fullvsfull2 = 1-pchisq((103.8-97.281),3)\
full2vssameintercept = 1-pchisq((106.6-103.8),2)\
\
#perform exhaustive search#\
results <- regsubsets(y~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11, data = data, nvmax = 8)\
sum.results = summary(results)\
mods = sum.results$which\
bic = sum.results$bic\
results.table = cbind(mods,bic)\
results.table[order(bic, decreasing = F),]\
\
results <- regsubsets(y~x1+x2+x3+x4+x6+x7+x9+x10, data = data, nvmax = 8)\
sum.results = summary(results)\
mods = sum.results$which\
bic = sum.results$bic\
results.table = cbind(mods,bic)\
results.table[order(bic, decreasing = F),]\
\
##Assumptions and Multicollinearity\
subset = cbind(data$x3, data$x4, data$x6, data$x7, data$x9, data$x10)\
new = data.frame(subset)\
plot(new)\
```\
\
```\{r\}\
library(mass)\
\
data = read.table('C:/Users/Ryan/Desktop/Stats/572/exam/spores.csv', header = TRUE, sep = ",", dec = ".")\
\
data$rh = factor(data$rh)\
data$temp = factor(data$temp)\
\
model = lm(y~rh+temp+rh*temp, data = data)\
\
plot(model)\
\
boxcox(model)\
\
log.model = lm(logy~rh+temp+rh*temp, data = data)\
\
plot(log.model)\
```}